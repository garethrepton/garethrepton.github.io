---
layout: post
title: Theory > Syntax
tags: c# patterns autofixture objectoriented software softwaredevelopment development
---

The longer I develop software, the more I realise just how important the time I took to properly learn the core theory and concepts of the things I've worked on has been over the years. Whilst I cant always apply them exactly how I'd like to, due to a variety of constraints, understanding them gives me the confidence to design things (iteratively or otherwise), breaking the complexity into more easily manageable chunks, and I don't tend to worry about them getting out of hand like I did before. It also gives me the confidence to push forward even when faced with the various less than optimal situations you can come across. Its very easy for a developer to discard/discredit core concepts they don't understand in favour of a simpler short term path for example, but short term thinking can very easily lead to spaghetti code, inflexible, and/or unscalable design. This is one way to end up with legacy unmaintainable code. 

Whilst you can develop working software without understanding the core concepts by following simple step by step guides and sticking to the rails you are provided, its a bit like getting a set of flat pack furniture from IKEA, you follow the rules, you build a cabinet. But if you were asked to build a wardrobe from scratch, you wouldn't know where to start (well, unless you went back to IKEA ;) ). Its the same with software, yes you can just learn some syntax and follow the rules, and quite often thats ok to start with, but get something that doesnt fit the mould, and its probably going to end up with you copying code off the internet, or freestyling something convoluted and unreadable. Theres also no way you could architect a solution this way, well, not a working and well designed one at least as you would only have previous "paint by numbers" code to refer to for each part.

The beautiful thing about understanding the core concepts are that they can be applied time and time again, in many different languages. Some things even apply across programming paradigms, for example since starting to learn functional programming I've noticed that a lot of the features in OO languages are actually from the functional world (Linq/Lambda is a very good example of this). Some of the OO patterns and practices are actually similar to functional ones too, just expressed very differently, for example defining small single behaviour interfaces, is not too dissimilar to the "Everything is a function" mindset you get in functional development, and Currying and Dependency Injection are similar at a very high level, but implemented very, very differently in the languages.

It also makes it much easier to learn a new language thats built on those concepts, because the concepts will be familiar, it will just have different syntax, which can probably be learnt fairly easily. There will be a massive amount of "Technical" features associated with a new language or platform that you'll also need to learn, and will be useful, but by understanding the underlying concepts as well as the syntax, your core design/code will be solid in any language (especially in OO :) ), and usually its easier to deal with small technical issues (usually) than it is to completely rework a design.  

Theres also a parallel here with business requirements too, you need to know the 'why' to properly understand the 'how' quite often. Yes you can get a set of predefined rules for a set of business requirements, but those rules won't allow you to learn the domain, its much better to understand the underlying reasons why things are done to get the understanding you need.  

There really are a myriad of reasons to learn the underlying theory and not just the syntax of a given language.  I'd encourage everyone using an OO language (e.g. C#/Java) to learn the underlying philosophy(or philosophies is probably more accurate) of OO, things like separating objects by their behaviour as opposed to the data they hold can really change the way you think about code, and massively improve its design. Then learning things like design patterns, and refactoring can change how you think again, and then TDD naturally follows on from this too and so on. 

Finally... always remember, there is a balance. I doubt theres a single application out there that's 'Pure' to its intended concepts and best practices, theres always some kind of tradeoff that needs to happen, whether thats timescales, skillsets or just the tech being used. Everything has compromises, if theres one thing I could go back and tell myself back when I first learnt OO, it would be that its ok to compromise (on occasion) when it makes sense to do it, its ok to put that business logic in a stored procedure if it makes sense given the circumstances, its ok not to have 100% code coverage etc... The main thing is that you're operating from a position of knowledge and consciously making those decisions as opposed to ignorance. Oh, and also... you do need to actually be able to write the associated code, knowing the theory will not teach you this ;). 

Try it if you haven't already...